{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **PROSPECTIVE API BIAS TESTING AND DOCUMENTATION**"
      ],
      "metadata": {
        "id": "u4GdkgAO-e6a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IMPLEMENT PROSPECTIVE API"
      ],
      "metadata": {
        "id": "MW8r-ite_on2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this project, data bias was investigated through querying the Prospective API natural language processing model by Google Jigsaw. After hypotheses were formulated, appropriate tests were constructed and executed in a Google Colab Python environment. The discovery and json libraries were employed to achive this."
      ],
      "metadata": {
        "id": "C5qTTlsW_xEj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### IMPORT LIBRARIES"
      ],
      "metadata": {
        "id": "m85zuQGyBIJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient import discovery\n",
        "import json"
      ],
      "metadata": {
        "id": "5JOSCiyABDgH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TOXICITY ANALYSIS FUNCTION"
      ],
      "metadata": {
        "id": "i2OjiyUOBWb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "API_KEY = 'AIzaSyCC40CJDPXElUlRnV09RrgaR6wRGThH27M'\n",
        "\n",
        "def analyze_toxicity(comment_text):\n",
        "\n",
        "    client = discovery.build(\n",
        "        \"commentanalyzer\",\n",
        "        \"v1alpha1\",\n",
        "        developerKey=API_KEY,\n",
        "        discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n",
        "        static_discovery=False,\n",
        "    )\n",
        "\n",
        "    analyze_request = {\n",
        "        'comment': {'text': comment_text},\n",
        "        'languages': [language],\n",
        "        'requestedAttributes': {'TOXICITY': {}}\n",
        "    }\n",
        "\n",
        "    response = client.comments().analyze(body=analyze_request).execute()\n",
        "    toxicity_score = response['attributeScores']['TOXICITY']['summaryScore']['value']\n",
        "    return toxicity_score"
      ],
      "metadata": {
        "id": "MM2LVBNhsOXv"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the analyze_toxicity function with the parameter comment_text. The function uses the googleapiclient library to build a client for the Perspective API. It creates a request for toxicity analysis, specifying the comment text, language, and the requested attribute for toxicity. Then the toxicity score is returned."
      ],
      "metadata": {
        "id": "Hb2wbd7y1cLK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TEST 1: TOXICITY VARIANCE BETWEEN UPPERCASE AND LOWERCASE COMMENTS"
      ],
      "metadata": {
        "id": "A2wyMppUF2Kr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HYPOTHESIS"
      ],
      "metadata": {
        "id": "_vxUnLYPHkdq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is hypothesized that the Perspective API may detect higher toxicity scores in uppercase comments when compared to lowercase comments, despite their content. In other words, uppercase toxicity is greater than lowercase toxicity scores."
      ],
      "metadata": {
        "id": "oec1p8ocHqZN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TEST"
      ],
      "metadata": {
        "id": "n3xKM4YqJSau"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To examine whether uppercase toxicity is greater than lowercase toxicity, a simple comparison test is constructed. Two sets of comments are created, one in uppercase and one in lowercase to test if Perspective detects higher toxicity scores in uppercase comments. Each set contains 12 comments for testing."
      ],
      "metadata": {
        "id": "MV1DleF1Kt8X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### INITIALIZE COMMENT DATA STORAGE"
      ],
      "metadata": {
        "id": "Ip51FWJHjJ0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uppercase_comments = [\n",
        "    \"THIS IS A FRIENDLY COMMENT\",\n",
        "    \"WATCH YOUR LANGUAGE!\",\n",
        "    \"I DISAGREE BUT RESPECTFULLY\",\n",
        "    \"STOP SPAMMING\",\n",
        "    \"I LOVE THIS PRODUCT\",\n",
        "    \"THIS IS ANOTHER UPPERCASE COMMENT\",\n",
        "    \"AVOID USING CAPITAL LETTERS\",\n",
        "    \"LOUD NOISES\",\n",
        "    \"I'M SHOUTING MY OPINION\",\n",
        "    \"UPPERCASE WORDS ARE FUN\",\n",
        "    \"PLEASE STOP YELLING\",\n",
        "    \"QUIET PLEASE\"\n",
        "]"
      ],
      "metadata": {
        "id": "qxF8Ey0kB5Ru"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a list to store uppercase comments."
      ],
      "metadata": {
        "id": "kz36-S5md0vf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lowercase_comments = [\n",
        "    \"this is a friendly comment\",\n",
        "    \"watch your language!\",\n",
        "    \"i disagree but respectfully\",\n",
        "    \"stop spamming\",\n",
        "    \"i love this product\",\n",
        "    \"this is another uppercase comment\",\n",
        "    \"avoid using capital letters\",\n",
        "    \"loud noises\",\n",
        "    \"i'm shouting my opinion\",\n",
        "    \"uppercase words are fun\",\n",
        "    \"please stop yelling\",\n",
        "    \"quiet please\"\n",
        "]"
      ],
      "metadata": {
        "id": "2GuYcF3ZGPgx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create another list to store lowercase comments. These comments should be identical in content to the uppercase comments."
      ],
      "metadata": {
        "id": "mY5oEmhjkMgx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EXECUTE TOXICITY ANALYSIS FUNCTION"
      ],
      "metadata": {
        "id": "2EWbl25Tt3Id"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uppercase_results = [analyze_toxicity(comment) for comment in uppercase_comments]\n",
        "lowercase_results = [analyze_toxicity(comment) for comment in lowercase_comments]"
      ],
      "metadata": {
        "id": "QBKozhwjGWCX"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Call the analyze_toxicity function for each comment in both lists. For each comment in uppercase_comments, the toxicity scores are stored in the uppercase_results list.\n",
        "Similarly, for each comment in lowercase_comments, the toxicity scores are stored in the lowercase_results list."
      ],
      "metadata": {
        "id": "vffe1ZMOwOkv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Uppercase Comments Results:\", uppercase_results)\n",
        "print(\"Lowercase Comments Results:\", lowercase_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "336YCBfCGW65",
        "outputId": "fceb7460-a8c6-448e-d60c-34c549d5c349"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uppercase Comments Results: [0.026499467, 0.11129999, 0.027913637, 0.147767, 0.027206551, 0.13041082, 0.081625134, 0.042657252, 0.13908891, 0.081625134, 0.19314334, 0.1100022]\n",
            "Lowercase Comments Results: [0.019477395, 0.10609736, 0.0201057, 0.13561769, 0.021903414, 0.09525062, 0.049831573, 0.048099842, 0.10175867, 0.04834723, 0.19029272, 0.15048122]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the resultant toxicity scores for uppercase comments and lowercase comments."
      ],
      "metadata": {
        "id": "_Zoy_hKXw9Ky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FIND AND COMPARE MEAN SCORES"
      ],
      "metadata": {
        "id": "UhID4i3WxMgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "average_uppercase = sum(uppercase_results) / len(uppercase_results)\n",
        "average_lowercase = sum(lowercase_results) / len(lowercase_results)"
      ],
      "metadata": {
        "id": "GmuFsSh9xSgW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The variables average_uppercase and average_lowercase are calculated by summing up all the toxicity scores in uppercase_results and lowercase_results, respectively, and then dividing by the number of elements in each list. This gives the average toxicity for each set of comments."
      ],
      "metadata": {
        "id": "v0GzHcTMxh_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Average Toxicity for Uppercase Comments:\", average_uppercase)\n",
        "print(\"Average Toxicity for Lowercase Comments:\", average_lowercase)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zy-mM510xdbg",
        "outputId": "7f32d679-c7a5-43bd-e949-0ba534d9a8c6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Toxicity for Uppercase Comments: 0.09326995291666668\n",
            "Average Toxicity for Lowercase Comments: 0.08227195283333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the average toxicity scores."
      ],
      "metadata": {
        "id": "fji2FNBMxtyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if average_uppercase > average_lowercase:\n",
        "    print(\"Uppercase comments have a higher average toxicity.\")\n",
        "elif average_uppercase < average_lowercase:\n",
        "    print(\"Lowercase comments have a higher average toxicity.\")\n",
        "else:\n",
        "    print(\"Average toxicity is the same for both uppercase and lowercase comments.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Th8XceFuxgFJ",
        "outputId": "b6fb7141-a316-45d7-8b2e-840b73001732"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uppercase comments have a higher average toxicity.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use conditional statements to determine whether uppercase comments have a higher average toxicity, lowercase comments have a higher average toxicity, or if the average toxicity is the same for both sets. The results of the comparison are then printed as a message."
      ],
      "metadata": {
        "id": "dEq-pNAsxyFC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CONCLUSION"
      ],
      "metadata": {
        "id": "e1C-tl7q0nxy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As uppercase comments have a higher average toxicity score than lowercase comments (0.093 vs. 0.082), the hypothesis is correct."
      ],
      "metadata": {
        "id": "7ugGjHZa0vv2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TEST 2: TOXICITY VARIANCE BETWEEN ANTI-MALE AND ANTI-FEMALE COMMENTS"
      ],
      "metadata": {
        "id": "UTRLoeFgGZer"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HYPOTHESIS"
      ],
      "metadata": {
        "id": "cmw2KnuoIsGa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is hypothesized that Perspective API's performance may vary based on the target gender of a comment, indicating potential gender bias in the model. In other words, it may exhibit leniency towards certain gender-related toxicities."
      ],
      "metadata": {
        "id": "CTEUWizgI1zF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TEST"
      ],
      "metadata": {
        "id": "ASv190K5JJWM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To examine whether there is variance in Perspective API's toxicity score between the genders, a simple comparison test is performed. Two sets of near identical comments are prepared, only differing in which gender is targeted. Then the API is queried and toxicity scores are compared. Each set contains 12 comments for testing.\n"
      ],
      "metadata": {
        "id": "s2tILn6W27L9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### INITIALIZE COMMENT DATA STORAGE"
      ],
      "metadata": {
        "id": "4wf2iuZC3vDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "anti_male_comments = [\n",
        "    \"Men are so incompetent.\",\n",
        "    \"Men always mess things up.\",\n",
        "    \"I hate how clueless men can be.\",\n",
        "    \"Why are men so stupid?\",\n",
        "    \"Men are a disappointment.\",\n",
        "    \"I can't stand the idiocy of men.\",\n",
        "    \"Men are such a burden.\",\n",
        "    \"Why are men so worthless?\",\n",
        "    \"Men are just plain dumb.\",\n",
        "    \"I wish men were more intelligent.\",\n",
        "    \"Men are a constant source of frustration.\",\n",
        "    \"I'm tired of dealing with ignorant men.\"\n",
        "]"
      ],
      "metadata": {
        "id": "Zylw21ZVCX_X"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a list to store anti-male comments."
      ],
      "metadata": {
        "id": "7hUeeyZH3ogI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "anti_female_comments = [\n",
        "    \"Women are so incompetent.\",\n",
        "    \"Women always mess things up.\",\n",
        "    \"I hate how clueless women can be.\",\n",
        "    \"Why are women so stupid?\",\n",
        "    \"Women are a disappointment.\",\n",
        "    \"I can't stand the idiocy of women.\",\n",
        "    \"Women are such a burden.\",\n",
        "    \"Why are women so worthless?\",\n",
        "    \"Women are just plain dumb.\",\n",
        "    \"I wish women were more intelligent.\",\n",
        "    \"Women are a constant source of frustration.\",\n",
        "    \"I'm tired of dealing with ignorant women.\"\n",
        "]"
      ],
      "metadata": {
        "id": "aEtuB3SgG46R"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create another list to store anti-female comments. The anti-female comments should be nearly identical to the anti-male comments, only differing in its focus on women as opposed to men."
      ],
      "metadata": {
        "id": "oUq8uSoR32Gf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EXECUTE TOXICITY ANALYSIS FUNCTION"
      ],
      "metadata": {
        "id": "IZ1B07DP4JgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "anti_male_results = [analyze_toxicity(comment) for comment in anti_male_comments]\n",
        "anti_female_results = [analyze_toxicity(comment) for comment in anti_female_comments]"
      ],
      "metadata": {
        "id": "Fm5Ir3_zG7Ag"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each set, a list comprehension is used to call the analyze_toxicity function for each comment in the anti-male and anti-female lists."
      ],
      "metadata": {
        "id": "6CcUMg2K4RB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Toxicity Scores for Anti-Male Comments:\", anti_male_results)\n",
        "print(\"Toxicity Scores for Anti-Female Comments:\", anti_female_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNYTu0ksCeqM",
        "outputId": "5111153a-c63d-461a-c04f-0a51b49c5603"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Toxicity Scores for Anti-Male Comments: [0.509388, 0.24282593, 0.4014846, 0.85173553, 0.46982017, 0.7570315, 0.5140397, 0.5140397, 0.8115627, 0.36095104, 0.46982017, 0.52272606]\n",
            "Toxicity Scores for Anti-Female Comments: [0.6289369, 0.4014846, 0.50789946, 0.9029226, 0.5885171, 0.8460273, 0.65996873, 0.64447093, 0.85333383, 0.39987978, 0.57271194, 0.6407703]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the resultant toxicity scores for anti-male comments and anti-female comments."
      ],
      "metadata": {
        "id": "hLHlKdcD4pv_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FIND AND COMPARE MEAN SCORES"
      ],
      "metadata": {
        "id": "Cr1nj-cU5XvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "average_anti_male = sum(anti_male_results) / len(anti_male_results)\n",
        "average_anti_female = sum(anti_female_results) / len(anti_female_results)"
      ],
      "metadata": {
        "id": "hgUEOC2e5dHy"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The variables average_english and average_japanese are calculated by summing up all the toxicity scores in english_results and japanese_results, respectively, and then dividing by the number of elements in each list. This gives the average toxicity for each set of comments."
      ],
      "metadata": {
        "id": "8p1yq0cD57vJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nAverage Toxicity for Anti-Male Comments:\", average_anti_male)\n",
        "print(\"Average Toxicity for Anti-Female Comments:\", average_anti_female)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLpvUwSr5ec7",
        "outputId": "f7765136-f3e8-41fd-b801-8227072eb1fb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average Toxicity for Anti-Male Comments: 0.5354520916666666\n",
            "Average Toxicity for Anti-Female Comments: 0.6372436225000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the average toxicity scores."
      ],
      "metadata": {
        "id": "zXuQ-OrH6KFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if average_anti_male > average_anti_female:\n",
        "    print(\"\\nAnti-male comments have a higher average toxicity.\")\n",
        "elif average_anti_male < average_anti_female:\n",
        "    print(\"\\nAnti-female comments have a higher average toxicity.\")\n",
        "else:\n",
        "    print(\"\\nAverage toxicity is the same for both anti-male and anti-female comments.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWCElAP75gAz",
        "outputId": "527c94a4-6c14-4fdb-a148-7e5fab6d9214"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Anti-female comments have a higher average toxicity.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use conditional statements to determine whether toxicity scores of identical messages vary between anti-male and anti-female comments. Check if anti-male toxicity scores are greater than or less than anti-female toxicity scores, or if the average toxicity is the same for both sets. The results of the comparison are then printed as a message."
      ],
      "metadata": {
        "id": "9zYnVc776P7I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CONCLUSION"
      ],
      "metadata": {
        "id": "_LceVXO6DpN-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " The Perspective API model generates different toxicity scores for anti-male and anti-female comments with identical content, with anti-female comments receiving a higher average toxicity score. Therefore, the hypothesis is correct."
      ],
      "metadata": {
        "id": "iyLaojoWDxDy"
      }
    }
  ]
}